{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below you will find a combination of a cleaning script and data summary script for the dataset from \n",
    "# Keep Vietnam Clean's (KVC) project regarding waste observations in Vietnam.\n",
    "# The cleaning script works as an ETL (extract, transform, load) pipeline for a dataset. \n",
    "# It ingests the .csv file from Anecdata for the project. \n",
    "# The data is then cleaned saved to your device as a new dataset.\n",
    "# Next, the new dataset is summarized in various pivot tables and summary variables.\n",
    "\n",
    "# Last updated in May 2023 by Carter Shields (carterishields@gmail.com, cis2af@virginia.edu)\n",
    "# For best results, run the .ipynb file in a jupyter notebook. \n",
    "# When running in jupyter notebook, for each of the following blocks, press the 'run' button above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset to your device using this link: https://www.anecdata.org/projects/view/477/data\n",
    "# If you know your file path name for the data, enter it when prompted in the 'file_input' block\n",
    "\n",
    "# If you do not know your file path name, run this next block of code to find it\n",
    "# Once you press run, it should navigate back to your desktop.\n",
    "# If it does not, go back to your desktop where you will see a pop-up that let's you navigate to your file\n",
    "# When you locate the data file, click open. \n",
    "# A text box will appear with a box containing words like this:\n",
    "# <_io.TextIOWrapper name='/Users/cartershields/Desktop/GSVS 4991/ObserveDebris_kinh_t__sinh_th_i_vi_t_nam-2022-12-20_06.28.21.csv' mode='r' encoding='UTF-8'>\n",
    "\n",
    "# Where you see the word name=, select all the text from the first ' (apostrophe) until the next ' (apostrophe). \n",
    "# Copy this text\n",
    "# Paste when prompted after running the 'file_input' block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "app = tk.Tk()\n",
    "\n",
    "app.title('Tkinter Dialog')\n",
    "app.geometry('600x350')\n",
    "\n",
    "text = tk.Text(app, height=12)\n",
    "\n",
    "text.grid(column=0, row=0, sticky='nsew')\n",
    "\n",
    "# Function to open the file dialog:\n",
    "\n",
    "def open_csv_file():\n",
    "    f = fd.askopenfile(filetypes=[('CSV files', '*.csv')], initialdir=\"D:/Downloads\")\n",
    "    text.insert('1.0', f)\n",
    "\n",
    "open_button = ttk.Button(app, text='Open a File', command=open_csv_file)\n",
    "open_button.grid(sticky='w', padx=250, pady=50)\n",
    "\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste the file path of the data set:/Users/cartershields/Desktop/GSVS 4991/kinh_t__sinh_th_i_vi_t_nam-2023-04-23_12.05.33.csv\n"
     ]
    }
   ],
   "source": [
    "# When you run this block, you will be prompted to enter the filepath that you just found or already knew\n",
    "# Press enter after you paste it\n",
    "\n",
    "file_input = input(\"Paste the file path of the data set:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block reads in the csv file from your device using the filename just provided\n",
    "filename = file_input\n",
    "df = pd.read_csv(filename, header = 'infer', index_col = 'observation_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations before cleaning =  1309\n",
      "Number of columns before cleaning =  103\n"
     ]
    }
   ],
   "source": [
    "# Creating an original summary for the data before cleaning\n",
    "shape = df.shape\n",
    "\n",
    "# Number of Observations\n",
    "print('Number of observations before cleaning = ', shape[0])\n",
    "\n",
    "# Number of Columns\n",
    "print('Number of columns before cleaning = ', shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset as a whole\n",
    "\n",
    "# Delete observations before April 2022\n",
    "\n",
    "recent_df = df.loc[(df['observed'] > '2022-03-31')]\n",
    "\n",
    "# recent_df is a data frame of all observations starting on 2022-04-01\n",
    "\n",
    "# Deleting columns that are no longer needed after the standardization of variables in 2022. \n",
    "\n",
    "df2 = recent_df.drop(['license', 'license_url', 'Metal_(%)', 'Plastic_(%)', 'Furniture_(%)', \n",
    "                      'Biodegradable_Organic_(%)', 'Balloons_(%)', 'Electronics_(%)', 'Glass_(%)', \n",
    "                      'Medical_Supplies___Personal_Hygiene_(%)', 'Vermin', 'Hazardous_Waste_(%)', 'Smoking_Related_(%)', \n",
    "                      'Mixed_Items_(%)', 'Other_(%)', 'Comments', 'Original_User', 'Waste_Container_Volume_(l)', \n",
    "                      'Image 1', 'Image 2', 'Image 3', 'Image 4', 'Image 5', 'Image 6', 'Image 7', 'Image 8', \n",
    "                      'Image 9', 'Image 10', 'Image 11', 'Image 12', 'Image 13', 'Image 14', 'Image 15', 'Image 16', \n",
    "                      'Image 17', 'Image 18', 'Image 19', 'Image 20', 'Image 21', 'Image 22', 'Image 23', 'Image 24', \n",
    "                      'Image 25', 'Image 26', 'Image 27', 'Image 28', 'Image 29', 'Image 30', 'Image 31', 'Image 32', \n",
    "                      'Image 33', 'Image 34', 'Image 35', 'Image 36', 'Image 37', 'Image 38', 'Image 39', 'Image 40', \n",
    "                      'Image 41', 'Image 42', 'Image 43', 'Image 44', 'Image 45'], axis = 1)\n",
    "\n",
    "# df2 is a data frame of the observations starting on 2022-04-01 with the unnecessary columns removed.\n",
    "\n",
    "# Change column title because some functions do not like working with parentheses\n",
    "df2[\"Waste_Vol_Liters\"] = df2['Waste_Volume_(l)']\n",
    "\n",
    "# Update data frame to only include observations within Vietnam.\n",
    "\n",
    "# Delete observations that do not contain location data or are not in Vietnam.\n",
    "# Uses the general range of between 6N and 25N for latitude and 100E and 115E for longitude for Vietnam.\n",
    "# This assumption is flawed if an observation is taken outside Vietnam but near the borders.\n",
    "\n",
    "df2 = df2.drop(df2[df2.lat < 6].index) \n",
    "df2 = df2.drop(df2[df2.lat > 25].index)\n",
    "df2 = df2.drop(df2[df2.lng > 115].index)\n",
    "df2 = df2.drop(df2[df2.lng < 100].index)\n",
    "\n",
    "# Removing NaN in \"What_is_near\" and \"Special_Hazards\" columns to be left blank\n",
    "\n",
    "df2['What_is_near'] = df2['What_is_near'].replace(np.nan, '0', regex=True)\n",
    "df2['Special_Hazards'] = df2['Special_Hazards'].replace(np.nan, '0', regex=True)\n",
    "\n",
    "# Creating new column titled \"Unique_ID\" that combines id and row_id\n",
    "# The Unique_ID column allows each child observation to have it's own unique identifier for future analysis.\n",
    "\n",
    "df2[\"Unique_ID\"] = df2['id'].astype(str) +\".\"+ df2[\"row_id\"].astype(str)\n",
    "\n",
    "# Moves Unique_ID from last position to first position in dataframe\n",
    "cols = list(df2.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "df2 = df2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4409231742e4>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Hypodermic_Needles'][df2['Special_Hazards'].str.contains(\"hypodermic needles\")] = 1\n",
      "<ipython-input-6-4409231742e4>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Batteries'][df2['Special_Hazards'].str.contains(\"batteries\")] = 1\n",
      "<ipython-input-6-4409231742e4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Paint_solvents_other_chemicals'][df2['Special_Hazards'].str.contains(\"paint, solvents, other chemicals\")] = 1\n",
      "/Users/cartershields/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "<ipython-input-6-4409231742e4>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Vermin'][df2['Special_Hazards'].str.contains(\"vermin (rats, cockroaches, etc.)\")] = 1\n",
      "<ipython-input-6-4409231742e4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Other_medical_waste'][df2['Special_Hazards'].str.contains(\"other medical wastes\")] = 1\n",
      "<ipython-input-6-4409231742e4>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['E-waste'][df2['Special_Hazards'].str.contains(\"e-waste\")] = 1\n",
      "<ipython-input-6-4409231742e4>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Cafe'][df2['What_is_near'].str.contains(\"Cafe\")] = 1\n",
      "<ipython-input-6-4409231742e4>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['School'][df2['What_is_near'].str.contains(\"School\")] = 1\n",
      "<ipython-input-6-4409231742e4>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Water'][df2['What_is_near'].str.contains(\"Water\")] = 1\n",
      "<ipython-input-6-4409231742e4>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Hospital'][df2['What_is_near'].str.contains(\"Hospital\")] = 1\n",
      "<ipython-input-6-4409231742e4>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Park'][df2['What_is_near'].str.contains(\"Park\")] = 1\n"
     ]
    }
   ],
   "source": [
    "# Cleaning variables that apply to just parent observations\n",
    "\n",
    "# Ignore the warning blocks, the code is working properly. The red here is not an error.\n",
    "\n",
    "# Change single column of special hazards to six binary columns\n",
    "# Inserts zeros into these columns for all observations\n",
    "df2['Hypodermic_Needles'] = '0'\n",
    "df2['Batteries'] = '0'\n",
    "df2['Paint_solvents_other_chemicals'] = '0'\n",
    "df2['Vermin'] = '0'\n",
    "df2['Other_medical_waste'] = '0'\n",
    "df2['E-waste'] = '0'\n",
    "\n",
    "# Inserts ones for observations when that specific hazard is present\n",
    "df2['Hypodermic_Needles'][df2['Special_Hazards'].str.contains(\"hypodermic needles\")] = 1\n",
    "df2['Batteries'][df2['Special_Hazards'].str.contains(\"batteries\")] = 1\n",
    "df2['Paint_solvents_other_chemicals'][df2['Special_Hazards'].str.contains(\"paint, solvents, other chemicals\")] = 1\n",
    "df2['Vermin'][df2['Special_Hazards'].str.contains(\"vermin (rats, cockroaches, etc.)\")] = 1\n",
    "df2['Other_medical_waste'][df2['Special_Hazards'].str.contains(\"other medical wastes\")] = 1\n",
    "df2['E-waste'][df2['Special_Hazards'].str.contains(\"e-waste\")] = 1\n",
    "\n",
    "\n",
    "# Change single column of \"what is near\" to five binary columns based on if contains feature\n",
    "\n",
    "# Inserts zeros into these columns for all observations\n",
    "df2['Cafe'] = '0'\n",
    "df2['School'] = '0'\n",
    "df2['Water'] = '0'\n",
    "df2['Hospital'] = '0'\n",
    "df2['Park'] = '0'\n",
    "\n",
    "# Inserts ones for observations when that location type is near\n",
    "df2['Cafe'][df2['What_is_near'].str.contains(\"Cafe\")] = 1\n",
    "df2['School'][df2['What_is_near'].str.contains(\"School\")] = 1\n",
    "df2['Water'][df2['What_is_near'].str.contains(\"Water\")] = 1\n",
    "df2['Hospital'][df2['What_is_near'].str.contains(\"Hospital\")] = 1\n",
    "df2['Park'][df2['What_is_near'].str.contains(\"Park\")] = 1\n",
    "\n",
    "# Ignore the warning blocks, the code is working properly. The red here is not an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning variables that apply to just child observations\n",
    "\n",
    "# Create column for the volume of a specific type of waste in an observation\n",
    "df2['Type_Liters'] = df2['Waste_Vol_Liters'] * (df2['Waste_Type_Percent_(%)']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of observations after cleaning =  268\n",
      "Number of columns after cleaning =  54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a summary for the new dataframe\n",
    "shape_new = df2.shape\n",
    "print()\n",
    "\n",
    "# Number of Observations (rows)\n",
    "print('Number of observations after cleaning = ', shape_new[0])\n",
    "\n",
    "# Number of Columns\n",
    "print('Number of columns after cleaning = ', shape_new[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file type you would like to output to (CSV or JSON; case sensitive):CSV\n",
      "File (CSV) outputted as: /Users/cartershields/Desktop/GSVS 4991/kinh_t__sinh_th_i_vi_t_nam-2023-04-23_12.05.33_CLEANED.csv\n"
     ]
    }
   ],
   "source": [
    "# Choosing an output for the cleaned data to be saved to your device.\n",
    "\n",
    "# User input either JSON or CSV to write the updated file to a local file.\n",
    "# Input is case sensitive.\n",
    "# If user tries to input another file type, it throws an error that loops back to the user needing to input again.\n",
    "\n",
    "# Cleaned data will be exported to the same directory as where the original data was.\n",
    "\n",
    "clean_csv = \"_CLEANED.csv\"\n",
    "new_csv = filename[:-4] + clean_csv\n",
    "\n",
    "clean_json = \"_CLEANED.json\"\n",
    "new_json = filename[:-4] + clean_json\n",
    "\n",
    "input_type = input(\"Enter the file type you would like to output to (CSV or JSON; case sensitive):\")\n",
    "\n",
    "if input_type == 'CSV':\n",
    "    data = os.path.join(os.getcwd())\n",
    "    output_file = os.path.join(data, new_csv)\n",
    "    df2.to_csv(output_file)\n",
    "    print('File (CSV) outputted as: ' + new_csv)\n",
    "elif file_type == 'JSON':\n",
    "    data = os.path.join(os.getcwd())\n",
    "    output_file = os.path.join(data, new_json)\n",
    "    df2.to_json(output_file)\n",
    "    print('File (JSON) outputted as: ' + new_json)\n",
    "else:\n",
    "    print('File type not found. Enter either CSV or JSON.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is the summary for the cleaned dataset. \n",
    "# If you only want to clean the dataset, you can stop here. \n",
    "# As more observations are added to the dataset, the script can be re-run to see the updated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARENT OBSERVATIONS PIVOT TABLE\n",
    "\n",
    "# Automated pivot table that shows observations as their whole site (referred to as parent observation):\n",
    "parent_pivot = df2.pivot_table(index=['id', 'lat', 'lng', 'Illegal_Dumping', 'Foul_Odor', 'Cafe', 'School', 'Water', \n",
    "                                      'Hospital', 'Park', 'Hypodermic_Needles', 'Batteries', \n",
    "                                      'Paint_solvents_other_chemicals', 'Vermin', 'Other_medical_waste', 'E-waste'], \n",
    "                           values=['Waste_Vol_Liters', 'row_id'], \n",
    "                           aggfunc={'Waste_Vol_Liters': 'min', 'row_id':'count'})\n",
    "print(parent_pivot)\n",
    "\n",
    "# df_pivot acts as a new dataframe of just the entire site observation (parent)\n",
    "# the pivot table shows the information pertaining to that entire site\n",
    "\n",
    "# If you are familiar with how pivot tables work in excel and have some basic knowledge of python:\n",
    "# you can customize the pivot table to include whichever variables are of interest to you\n",
    "# If you include columns that have NAs, the pivot table will only include the rows that have completed values for all \n",
    "# rows in all columns you selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parent pivot table you made above as a csv to your device\n",
    "\n",
    "pp_csv = \"_PARENT_PIVOT.csv\"\n",
    "pp_title = filename[:-4] + pp_csv\n",
    "\n",
    "pp_exp = os.path.join(os.getcwd())\n",
    "output_file_parent_pivot = os.path.join(pp_exp, pp_title)\n",
    "parent_pivot.to_csv(output_file_parent_pivot)\n",
    "print('File (CSV) outputted as: ' + pp_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHILD OBSERVATIONS PIVOT TABLE\n",
    "child_pivot = df2.pivot_table(index=['Unique_ID', 'lat', 'lng', 'Type_Liters'], \n",
    "                           values=['Waste_Vol_Liters', 'Waste_Type_Percent_(%)', 'Waste_Type'], \n",
    "                           aggfunc={'Waste_Vol_Liters': 'min', 'Waste_Type_Percent_(%)': 'min', 'Waste_Type': 'min'})\n",
    "print(child_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the child pivot table you made above as a csv to your device\n",
    "\n",
    "cp_csv = \"_CHILD_PIVOT.csv\"\n",
    "cp_title = filename[:-4] + cp_csv\n",
    "\n",
    "cp_exp = os.path.join(os.getcwd())\n",
    "output_file_child_pivot = os.path.join(cp_exp, cp_title)\n",
    "child_pivot.to_csv(output_file_child_pivot)\n",
    "print('File (CSV) outputted as: ' + cp_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Volume by Waste Type (using child obs)\n",
    "\n",
    "# Read in the parent pivot file \n",
    "\n",
    "filename_parent_pivot = pp_title\n",
    "df_pp = pd.read_csv(filename_parent_pivot, header = 'infer', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vol = df_pp['Waste_Vol_Liters'].sum()\n",
    "type_liters = df2.groupby([\"Waste_Type\"]).Type_Liters.sum()\n",
    "type_perc_of_total = round((type_liters / total_vol) *100,2)\n",
    "vol_big = pd.concat([type_liters, type_perc_of_total], axis=1)\n",
    "\n",
    "# Issue is it labels both columns as type_liters\n",
    "\n",
    "# Save the above table as a csv to your device to then be imported back to change column names\n",
    "# No need to actually use this file for anything\n",
    "\n",
    "vol_big_csv = \"_VOLUME_WRONG_TITLES.csv\"\n",
    "vol_big_title = filename[:-4] + vol_big_csv\n",
    "\n",
    "vol_big_exp = os.path.join(os.getcwd())\n",
    "output_file_vol_big = os.path.join(vol_big_exp, vol_big_title)\n",
    "vol_big.to_csv(output_file_vol_big)\n",
    "\n",
    "# Read in previous file\n",
    "\n",
    "filename_vol_big = vol_big_title\n",
    "df_vb = pd.read_csv(filename_vol_big, header = 'infer', index_col = 'Waste_Type')\n",
    "\n",
    "# Writes new column titles for this table to then be saved to your device\n",
    "# This is the file to look at for volume summary\n",
    "\n",
    "df_vb1 = df_vb.rename(columns={'Type_Liters.1': 'Type_Percent_of_Total_Volume'})\n",
    "volume_csv = \"_VOLUME_SUMMARY.csv\"\n",
    "volume_title = filename[:-4] + volume_csv\n",
    "\n",
    "volume_exp = os.path.join(os.getcwd())\n",
    "output_file_volume = os.path.join(volume_exp, volume_title)\n",
    "df_vb1.to_csv(output_file_volume)\n",
    "print('File (CSV) outputted as: ' + volume_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now delete the file that ends in \"_VOLUME_WRONG_TITLES.csv\" if you would like"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
